{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 7 - Summary Classification: Comparison of Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Load Data Set\n",
    "\n",
    "For the last session, we are working with a new data set - but with the same structure: The Fashion MNIST Dataset. Each image in the Fashion MNIST dataset is again 28x28 pixels, unrolled into a 784-dimensional vector for modeling (our input space). We transfer the labels to one-hot encoded targets.\n",
    "\n",
    "The original MNIST dataset (digits) serves as a benchmark for machine learning algorithms, as it presents a relatively simple, yet meaningful task: identifying handwritten digits. Despite its simplicity, the MNIST dataset is a great starting point for building and evaluating classification models.\n",
    "\n",
    "**Task:**\n",
    "\n",
    "As a first step, you only have to go through the next steps and inspect the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images are 28x28 NumPy arrays, with pixel values ranging from 0 to 255. The *labels* are an array of integers, ranging from 0 to 9. These correspond to the *class* of clothing the image represents:\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Label</th>\n",
    "    <th>Class</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>0</td>\n",
    "    <td>T-shirt/top</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>1</td>\n",
    "    <td>Trouser</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>2</td>\n",
    "    <td>Pullover</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>3</td>\n",
    "    <td>Dress</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>4</td>\n",
    "    <td>Coat</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>5</td>\n",
    "    <td>Sandal</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>6</td>\n",
    "    <td>Shirt</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>7</td>\n",
    "    <td>Sneaker</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>8</td>\n",
    "    <td>Bag</td>\n",
    "  </tr>\n",
    "    <tr>\n",
    "    <td>9</td>\n",
    "    <td>Ankle boot</td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "Each image is mapped to a single label. Since the *class names* are not included with the dataset, store them here to use later when plotting the images:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T13:46:44.541956Z",
     "start_time": "2024-11-22T13:46:44.520896Z"
    }
   },
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T13:48:00.495501Z",
     "start_time": "2024-11-22T13:47:55.794508Z"
    }
   },
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "# Load MNIST dataset\n",
    "#mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "#X, y = mnist[\"data\"], mnist[\"target\"].astype(int)\n",
    "\n",
    "# Fetch the Fashion-MNIST dataset\n",
    "fashion_mnist = fetch_openml('Fashion-MNIST', version=1, as_frame=False)\n",
    "# Separate the features (X) and labels (y)\n",
    "X, y = fashion_mnist['data'], fashion_mnist['target']\n",
    "# Convert labels to integers (if needed)\n",
    "y = y.astype(np.int64)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T13:48:33.181605Z",
     "start_time": "2024-11-22T13:48:32.722913Z"
    }
   },
   "source": [
    "# One-hot encode the labels\n",
    "encoder = OneHotEncoder(sparse_output=False, categories='auto')\n",
    "y_one_hot = encoder.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "# Split into training and test sets\n",
    "# TODO: Change train size\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, train_size=10000, test_size=10000, random_state=42, stratify=y)\n",
    "\n",
    "# Display shapes of the resulting datasets\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Test set shape:\", X_test.shape, y_test.shape)\n",
    "\n",
    "#TODO: Add normalization\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "print(X_train.max())\n",
    "\n",
    "# Reshape the data to include a single channel for grayscale images (28x28x1)\n",
    "X_train_cnn = X_train.reshape(-1, 28, 28, 1)\n",
    "X_test_cnn = X_test.reshape(-1, 28, 28, 1)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (10000, 784) (10000, 10)\n",
      "Test set shape: (10000, 784) (10000, 10)\n",
      "1.0\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T13:49:31.917550Z",
     "start_time": "2024-11-22T13:49:31.332667Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(X_train_cnn[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[np.argmax(y_train[i])])\n",
    "plt.show()"
   ],
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "In FT2Font: Can not load face (invalid stream operation; error code 0x55)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "File \u001B[1;32m~\\anaconda3\\envs\\deepEnv\\lib\\site-packages\\IPython\\core\\formatters.py:343\u001B[0m, in \u001B[0;36mBaseFormatter.__call__\u001B[1;34m(self, obj)\u001B[0m\n\u001B[0;32m    341\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[0;32m    342\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 343\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mprinter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    344\u001B[0m \u001B[38;5;66;03m# Finally look for special method names\u001B[39;00m\n\u001B[0;32m    345\u001B[0m method \u001B[38;5;241m=\u001B[39m get_real_method(obj, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprint_method)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deepEnv\\lib\\site-packages\\IPython\\core\\pylabtools.py:170\u001B[0m, in \u001B[0;36mprint_figure\u001B[1;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001B[0m\n\u001B[0;32m    167\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbackend_bases\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m FigureCanvasBase\n\u001B[0;32m    168\u001B[0m     FigureCanvasBase(fig)\n\u001B[1;32m--> 170\u001B[0m fig\u001B[38;5;241m.\u001B[39mcanvas\u001B[38;5;241m.\u001B[39mprint_figure(bytes_io, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkw)\n\u001B[0;32m    171\u001B[0m data \u001B[38;5;241m=\u001B[39m bytes_io\u001B[38;5;241m.\u001B[39mgetvalue()\n\u001B[0;32m    172\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m fmt \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msvg\u001B[39m\u001B[38;5;124m'\u001B[39m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deepEnv\\lib\\site-packages\\matplotlib\\backend_bases.py:2175\u001B[0m, in \u001B[0;36mFigureCanvasBase.print_figure\u001B[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001B[0m\n\u001B[0;32m   2172\u001B[0m     \u001B[38;5;66;03m# we do this instead of `self.figure.draw_without_rendering`\u001B[39;00m\n\u001B[0;32m   2173\u001B[0m     \u001B[38;5;66;03m# so that we can inject the orientation\u001B[39;00m\n\u001B[0;32m   2174\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(renderer, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_draw_disabled\u001B[39m\u001B[38;5;124m\"\u001B[39m, nullcontext)():\n\u001B[1;32m-> 2175\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfigure\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdraw\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrenderer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2176\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m bbox_inches:\n\u001B[0;32m   2177\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m bbox_inches \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtight\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deepEnv\\lib\\site-packages\\matplotlib\\artist.py:95\u001B[0m, in \u001B[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001B[1;34m(artist, renderer, *args, **kwargs)\u001B[0m\n\u001B[0;32m     93\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(draw)\n\u001B[0;32m     94\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdraw_wrapper\u001B[39m(artist, renderer, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m---> 95\u001B[0m     result \u001B[38;5;241m=\u001B[39m draw(artist, renderer, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     96\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m renderer\u001B[38;5;241m.\u001B[39m_rasterizing:\n\u001B[0;32m     97\u001B[0m         renderer\u001B[38;5;241m.\u001B[39mstop_rasterizing()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deepEnv\\lib\\site-packages\\matplotlib\\artist.py:72\u001B[0m, in \u001B[0;36mallow_rasterization.<locals>.draw_wrapper\u001B[1;34m(artist, renderer)\u001B[0m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m artist\u001B[38;5;241m.\u001B[39mget_agg_filter() \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     70\u001B[0m         renderer\u001B[38;5;241m.\u001B[39mstart_filter()\n\u001B[1;32m---> 72\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdraw\u001B[49m\u001B[43m(\u001B[49m\u001B[43martist\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrenderer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     73\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     74\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m artist\u001B[38;5;241m.\u001B[39mget_agg_filter() \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deepEnv\\lib\\site-packages\\matplotlib\\figure.py:3162\u001B[0m, in \u001B[0;36mFigure.draw\u001B[1;34m(self, renderer)\u001B[0m\n\u001B[0;32m   3159\u001B[0m             \u001B[38;5;66;03m# ValueError can occur when resizing a window.\u001B[39;00m\n\u001B[0;32m   3161\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpatch\u001B[38;5;241m.\u001B[39mdraw(renderer)\n\u001B[1;32m-> 3162\u001B[0m     \u001B[43mmimage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_draw_list_compositing_images\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   3163\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrenderer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43martists\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msuppressComposite\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3165\u001B[0m     renderer\u001B[38;5;241m.\u001B[39mclose_group(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfigure\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m   3166\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deepEnv\\lib\\site-packages\\matplotlib\\image.py:132\u001B[0m, in \u001B[0;36m_draw_list_compositing_images\u001B[1;34m(renderer, parent, artists, suppress_composite)\u001B[0m\n\u001B[0;32m    130\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m not_composite \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m has_images:\n\u001B[0;32m    131\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m a \u001B[38;5;129;01min\u001B[39;00m artists:\n\u001B[1;32m--> 132\u001B[0m         \u001B[43ma\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdraw\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrenderer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    133\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    134\u001B[0m     \u001B[38;5;66;03m# Composite any adjacent images together\u001B[39;00m\n\u001B[0;32m    135\u001B[0m     image_group \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deepEnv\\lib\\site-packages\\matplotlib\\artist.py:72\u001B[0m, in \u001B[0;36mallow_rasterization.<locals>.draw_wrapper\u001B[1;34m(artist, renderer)\u001B[0m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m artist\u001B[38;5;241m.\u001B[39mget_agg_filter() \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     70\u001B[0m         renderer\u001B[38;5;241m.\u001B[39mstart_filter()\n\u001B[1;32m---> 72\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdraw\u001B[49m\u001B[43m(\u001B[49m\u001B[43martist\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrenderer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     73\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     74\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m artist\u001B[38;5;241m.\u001B[39mget_agg_filter() \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deepEnv\\lib\\site-packages\\matplotlib\\axes\\_base.py:3137\u001B[0m, in \u001B[0;36m_AxesBase.draw\u001B[1;34m(self, renderer)\u001B[0m\n\u001B[0;32m   3134\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m artists_rasterized:\n\u001B[0;32m   3135\u001B[0m     _draw_rasterized(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfigure, artists_rasterized, renderer)\n\u001B[1;32m-> 3137\u001B[0m \u001B[43mmimage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_draw_list_compositing_images\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   3138\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrenderer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43martists\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfigure\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msuppressComposite\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3140\u001B[0m renderer\u001B[38;5;241m.\u001B[39mclose_group(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maxes\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m   3141\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mstale \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deepEnv\\lib\\site-packages\\matplotlib\\image.py:132\u001B[0m, in \u001B[0;36m_draw_list_compositing_images\u001B[1;34m(renderer, parent, artists, suppress_composite)\u001B[0m\n\u001B[0;32m    130\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m not_composite \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m has_images:\n\u001B[0;32m    131\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m a \u001B[38;5;129;01min\u001B[39;00m artists:\n\u001B[1;32m--> 132\u001B[0m         \u001B[43ma\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdraw\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrenderer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    133\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    134\u001B[0m     \u001B[38;5;66;03m# Composite any adjacent images together\u001B[39;00m\n\u001B[0;32m    135\u001B[0m     image_group \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deepEnv\\lib\\site-packages\\matplotlib\\artist.py:72\u001B[0m, in \u001B[0;36mallow_rasterization.<locals>.draw_wrapper\u001B[1;34m(artist, renderer)\u001B[0m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m artist\u001B[38;5;241m.\u001B[39mget_agg_filter() \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     70\u001B[0m         renderer\u001B[38;5;241m.\u001B[39mstart_filter()\n\u001B[1;32m---> 72\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdraw\u001B[49m\u001B[43m(\u001B[49m\u001B[43martist\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrenderer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     73\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     74\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m artist\u001B[38;5;241m.\u001B[39mget_agg_filter() \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deepEnv\\lib\\site-packages\\matplotlib\\axis.py:1431\u001B[0m, in \u001B[0;36mAxis.draw\u001B[1;34m(self, renderer)\u001B[0m\n\u001B[0;32m   1429\u001B[0m \u001B[38;5;66;03m# Shift label away from axes to avoid overlapping ticklabels.\u001B[39;00m\n\u001B[0;32m   1430\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_label_position(renderer)\n\u001B[1;32m-> 1431\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlabel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdraw\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrenderer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1433\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_offset_text_position(tlb1, tlb2)\n\u001B[0;32m   1434\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moffsetText\u001B[38;5;241m.\u001B[39mset_text(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmajor\u001B[38;5;241m.\u001B[39mformatter\u001B[38;5;241m.\u001B[39mget_offset())\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deepEnv\\lib\\site-packages\\matplotlib\\artist.py:72\u001B[0m, in \u001B[0;36mallow_rasterization.<locals>.draw_wrapper\u001B[1;34m(artist, renderer)\u001B[0m\n\u001B[0;32m     69\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m artist\u001B[38;5;241m.\u001B[39mget_agg_filter() \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     70\u001B[0m         renderer\u001B[38;5;241m.\u001B[39mstart_filter()\n\u001B[1;32m---> 72\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdraw\u001B[49m\u001B[43m(\u001B[49m\u001B[43martist\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrenderer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     73\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     74\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m artist\u001B[38;5;241m.\u001B[39mget_agg_filter() \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deepEnv\\lib\\site-packages\\matplotlib\\text.py:751\u001B[0m, in \u001B[0;36mText.draw\u001B[1;34m(self, renderer)\u001B[0m\n\u001B[0;32m    748\u001B[0m renderer\u001B[38;5;241m.\u001B[39mopen_group(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_gid())\n\u001B[0;32m    750\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_cm_set(text\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_wrapped_text()):\n\u001B[1;32m--> 751\u001B[0m     bbox, info, descent \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_layout\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrenderer\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    752\u001B[0m     trans \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_transform()\n\u001B[0;32m    754\u001B[0m     \u001B[38;5;66;03m# don't use self.get_position here, which refers to text\u001B[39;00m\n\u001B[0;32m    755\u001B[0m     \u001B[38;5;66;03m# position in Text:\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deepEnv\\lib\\site-packages\\matplotlib\\text.py:373\u001B[0m, in \u001B[0;36mText._get_layout\u001B[1;34m(self, renderer)\u001B[0m\n\u001B[0;32m    370\u001B[0m ys \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m    372\u001B[0m \u001B[38;5;66;03m# Full vertical extent of font, including ascenders and descenders:\u001B[39;00m\n\u001B[1;32m--> 373\u001B[0m _, lp_h, lp_d \u001B[38;5;241m=\u001B[39m \u001B[43m_get_text_metrics_with_cache\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    374\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrenderer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mlp\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fontproperties\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    375\u001B[0m \u001B[43m    \u001B[49m\u001B[43mismath\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mTeX\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_usetex\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdpi\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfigure\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdpi\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    376\u001B[0m min_dy \u001B[38;5;241m=\u001B[39m (lp_h \u001B[38;5;241m-\u001B[39m lp_d) \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_linespacing\n\u001B[0;32m    378\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, line \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(lines):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deepEnv\\lib\\site-packages\\matplotlib\\text.py:69\u001B[0m, in \u001B[0;36m_get_text_metrics_with_cache\u001B[1;34m(renderer, text, fontprop, ismath, dpi)\u001B[0m\n\u001B[0;32m     66\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Call ``renderer.get_text_width_height_descent``, caching the results.\"\"\"\u001B[39;00m\n\u001B[0;32m     67\u001B[0m \u001B[38;5;66;03m# Cached based on a copy of fontprop so that later in-place mutations of\u001B[39;00m\n\u001B[0;32m     68\u001B[0m \u001B[38;5;66;03m# the passed-in argument do not mess up the cache.\u001B[39;00m\n\u001B[1;32m---> 69\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_get_text_metrics_with_cache_impl\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     70\u001B[0m \u001B[43m    \u001B[49m\u001B[43mweakref\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mref\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrenderer\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfontprop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mismath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdpi\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deepEnv\\lib\\site-packages\\matplotlib\\text.py:77\u001B[0m, in \u001B[0;36m_get_text_metrics_with_cache_impl\u001B[1;34m(renderer_ref, text, fontprop, ismath, dpi)\u001B[0m\n\u001B[0;32m     73\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mlru_cache(\u001B[38;5;241m4096\u001B[39m)\n\u001B[0;32m     74\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_get_text_metrics_with_cache_impl\u001B[39m(\n\u001B[0;32m     75\u001B[0m         renderer_ref, text, fontprop, ismath, dpi):\n\u001B[0;32m     76\u001B[0m     \u001B[38;5;66;03m# dpi is unused, but participates in cache invalidation (via the renderer).\u001B[39;00m\n\u001B[1;32m---> 77\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mrenderer_ref\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_text_width_height_descent\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfontprop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mismath\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deepEnv\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:219\u001B[0m, in \u001B[0;36mRendererAgg.get_text_width_height_descent\u001B[1;34m(self, s, prop, ismath)\u001B[0m\n\u001B[0;32m    215\u001B[0m     ox, oy, width, height, descent, font_image \u001B[38;5;241m=\u001B[39m \\\n\u001B[0;32m    216\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmathtext_parser\u001B[38;5;241m.\u001B[39mparse(s, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdpi, prop)\n\u001B[0;32m    217\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m width, height, descent\n\u001B[1;32m--> 219\u001B[0m font \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_prepare_font\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprop\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    220\u001B[0m font\u001B[38;5;241m.\u001B[39mset_text(s, \u001B[38;5;241m0.0\u001B[39m, flags\u001B[38;5;241m=\u001B[39mget_hinting_flag())\n\u001B[0;32m    221\u001B[0m w, h \u001B[38;5;241m=\u001B[39m font\u001B[38;5;241m.\u001B[39mget_width_height()  \u001B[38;5;66;03m# width and height of unrotated string\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deepEnv\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:253\u001B[0m, in \u001B[0;36mRendererAgg._prepare_font\u001B[1;34m(self, font_prop)\u001B[0m\n\u001B[0;32m    249\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_prepare_font\u001B[39m(\u001B[38;5;28mself\u001B[39m, font_prop):\n\u001B[0;32m    250\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    251\u001B[0m \u001B[38;5;124;03m    Get the `.FT2Font` for *font_prop*, clear its buffer, and set its size.\u001B[39;00m\n\u001B[0;32m    252\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 253\u001B[0m     font \u001B[38;5;241m=\u001B[39m \u001B[43mget_font\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fontManager\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_find_fonts_by_props\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfont_prop\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    254\u001B[0m     font\u001B[38;5;241m.\u001B[39mclear()\n\u001B[0;32m    255\u001B[0m     size \u001B[38;5;241m=\u001B[39m font_prop\u001B[38;5;241m.\u001B[39mget_size_in_points()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deepEnv\\lib\\site-packages\\matplotlib\\font_manager.py:1560\u001B[0m, in \u001B[0;36mget_font\u001B[1;34m(font_filepaths, hinting_factor)\u001B[0m\n\u001B[0;32m   1557\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m hinting_factor \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1558\u001B[0m     hinting_factor \u001B[38;5;241m=\u001B[39m mpl\u001B[38;5;241m.\u001B[39mrcParams[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext.hinting_factor\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m-> 1560\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_get_font\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1561\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# must be a tuple to be cached\u001B[39;49;00m\n\u001B[0;32m   1562\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpaths\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1563\u001B[0m \u001B[43m    \u001B[49m\u001B[43mhinting_factor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1564\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_kerning_factor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmpl\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrcParams\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtext.kerning_factor\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1565\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# also key on the thread ID to prevent segfaults with multi-threading\u001B[39;49;00m\n\u001B[0;32m   1566\u001B[0m \u001B[43m    \u001B[49m\u001B[43mthread_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mthreading\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_ident\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1567\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deepEnv\\lib\\site-packages\\matplotlib\\font_manager.py:1502\u001B[0m, in \u001B[0;36m_get_font\u001B[1;34m(font_filepaths, hinting_factor, _kerning_factor, thread_id)\u001B[0m\n\u001B[0;32m   1499\u001B[0m \u001B[38;5;129m@lru_cache\u001B[39m(\u001B[38;5;241m64\u001B[39m)\n\u001B[0;32m   1500\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_get_font\u001B[39m(font_filepaths, hinting_factor, \u001B[38;5;241m*\u001B[39m, _kerning_factor, thread_id):\n\u001B[0;32m   1501\u001B[0m     first_fontpath, \u001B[38;5;241m*\u001B[39mrest \u001B[38;5;241m=\u001B[39m font_filepaths\n\u001B[1;32m-> 1502\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mft2font\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mFT2Font\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1503\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfirst_fontpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhinting_factor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1504\u001B[0m \u001B[43m        \u001B[49m\u001B[43m_fallback_list\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\n\u001B[0;32m   1505\u001B[0m \u001B[43m            \u001B[49m\u001B[43mft2font\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mFT2Font\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1506\u001B[0m \u001B[43m                \u001B[49m\u001B[43mfpath\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhinting_factor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1507\u001B[0m \u001B[43m                \u001B[49m\u001B[43m_kerning_factor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_kerning_factor\u001B[49m\n\u001B[0;32m   1508\u001B[0m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1509\u001B[0m \u001B[43m            \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mfpath\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mrest\u001B[49m\n\u001B[0;32m   1510\u001B[0m \u001B[43m        \u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1511\u001B[0m \u001B[43m        \u001B[49m\u001B[43m_kerning_factor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_kerning_factor\u001B[49m\n\u001B[0;32m   1512\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: In FT2Font: Can not load face (invalid stream operation; error code 0x55)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 25 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "## 7.2 Applying the LeNet-5 Architecture\n",
    "\n",
    "We will continue to use the **LeNet-5 architecture**, a classic CNN architecture designed by Yann LeCun for handwritten digit recognition. LeNet-5 is well-suited for the MNIST dataset and includes several convolutional and pooling layers, followed by fully connected layers. \n",
    "\n",
    "![](lenet5.svg)\n",
    "\n",
    "* Input Layer: Accepts 28x28 grayscale images as input, with each image normalized to a range of 0â€“1 (we added padding).\n",
    "* Convolutional Layer 1: Applies 6 filters of size 5x5 with stride 1 and ReLU activation, producing 6 feature maps. The resulting feature maps have dimensions of 24x24.\n",
    "* Pooling Layer 1 (Average Pooling): Averages over 2x2 regions, reducing each feature map to a size of 12x12. Pooling reduces the spatial dimensions and adds robustness to small spatial translations.\n",
    "* Convolutional Layer 2: Applies 16 filters of size 5x5 with stride 1 and ReLU activation, producing 16 feature maps. The resulting feature maps have dimensions of 8x8.\n",
    "* Pooling Layer 2 (Average Pooling): Another 2x2 average pooling layer, reducing each feature map to a size of 4x4.\n",
    "* Fully Connected Layers:\n",
    "   - Fully Connected Layer 1: Flattens the output from the convolutional layers and connects to a fully connected layer with 120 neurons and ReLU activation.\n",
    "   - Fully Connected Layer 2: Connects to a fully connected layer with 84 neurons and ReLU activation.\n",
    "* Output Layer: The final layer is a fully connected layer with 10 neurons and softmax activation, used for classification into the 10 digit classes.\n",
    "\n",
    "**Tasks:**\n",
    "\n",
    "Your tasks are to try out some variations:\n",
    "\n",
    "* increasing training data (for further variations might have to go back to smaller data set again to speed up training)\n",
    "* using normalization on the input data (gray scale values are encoded from 0 to 255 = scale it into the range $[0,1]$)\n",
    "* activation function (last week we already used ReLU, but originally LeNet used sigmoid): compare ReLU and sigmoid (on smaller training data set); how does this interacts with normalization?\n",
    "* adding Dropout as regularization\n",
    "* using early stopping\n",
    "* and Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-21T23:19:00.181048600Z",
     "start_time": "2024-11-21T23:18:47.915903900Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _errors: The specified procedure could not be found.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtf\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01moptimizers\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlegacy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Adam\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcallbacks\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m EarlyStopping\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# Define the LeNet-5 architecture\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deepEnv\\lib\\site-packages\\keras\\_tf_keras\\keras\\__init__.py:7\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"DO NOT EDIT.\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \n\u001B[0;32m      3\u001B[0m \u001B[38;5;124;03mThis file was autogenerated. Do not edit it by hand,\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;124;03msince your modifications would be overwritten.\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m----> 7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m activations\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m applications\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m callbacks\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deepEnv\\lib\\site-packages\\keras\\__init__.py:4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# DO NOT EDIT. Generated by api_gen.sh\u001B[39;00m\n\u001B[1;32m----> 4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DTypePolicy\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m FloatDTypePolicy\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Function\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deepEnv\\lib\\site-packages\\keras\\api\\__init__.py:31\u001B[0m\n\u001B[0;32m     29\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m random\n\u001B[0;32m     30\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m regularizers\n\u001B[1;32m---> 31\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m saving\n\u001B[0;32m     32\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tree\n\u001B[0;32m     33\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m utils\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deepEnv\\lib\\site-packages\\keras\\api\\saving\\__init__.py:7\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"DO NOT EDIT.\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \n\u001B[0;32m      3\u001B[0m \u001B[38;5;124;03mThis file was autogenerated. Do not edit it by hand,\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;124;03msince your modifications would be overwritten.\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m----> 7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msaving\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfile_editor\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m KerasFileEditor\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msaving\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mobject_registration\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m CustomObjectScope\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mkeras\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msrc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msaving\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mobject_registration\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     10\u001B[0m     CustomObjectScope \u001B[38;5;28;01mas\u001B[39;00m custom_object_scope,\n\u001B[0;32m     11\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deepEnv\\lib\\site-packages\\keras\\src\\saving\\file_editor.py:6\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpprint\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mzipfile\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mh5py\u001B[39;00m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mrich\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconsole\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\deepEnv\\lib\\site-packages\\h5py\\__init__.py:25\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;66;03m# --- Library setup -----------------------------------------------------------\u001B[39;00m\n\u001B[0;32m     20\u001B[0m \n\u001B[0;32m     21\u001B[0m \u001B[38;5;66;03m# When importing from the root of the unpacked tarball or git checkout,\u001B[39;00m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;66;03m# Python sees the \"h5py\" source directory and tries to load it, which fails.\u001B[39;00m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;66;03m# We tried working around this by using \"package_dir\" but that breaks Cython.\u001B[39;00m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 25\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _errors\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:\n\u001B[0;32m     27\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mos\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpath\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01m_op\u001B[39;00m\n",
      "\u001B[1;31mImportError\u001B[0m: DLL load failed while importing _errors: The specified procedure could not be found."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define the LeNet-5 architecture\n",
    "model_lenet5 = tf.keras.models.Sequential([\n",
    "    # Convolutional Layer 1: 6 filters of size 5x5, stride 1, with ReLU activation\n",
    "    # TODO: activation can be replaced with 'relu' instead of 'sigmoid'\n",
    "    tf.keras.layers.Conv2D(6, kernel_size=(5, 5), strides=1, activation='sigmoid', input_shape=(28, 28, 1), padding='same'),\n",
    "    # TODO: Batch normalization - remove the single line for Conv2D and replace it by the three following steps\n",
    "    #tf.keras.layers.Conv2D(6, kernel_size=(5, 5), strides=1, input_shape=(28, 28, 1)),\n",
    "    #tf.keras.layers.BatchNormalization(),\n",
    "    #tf.keras.layers.Activation('relu'),\n",
    "    # Average Pooling Layer 1: pool size 2x2\n",
    "    tf.keras.layers.AveragePooling2D(pool_size=(2, 2), strides=2),\n",
    "    # Convolutional Layer 2: 16 filters of size 5x5, stride 1, with ReLU activation\n",
    "    tf.keras.layers.Conv2D(16, kernel_size=(5, 5), strides=1, activation='sigmoid', padding='same'),\n",
    "    # TODO: Batch normalization - remove the single line for Conv2D and replace it by the three following steps\n",
    "    #tf.keras.layers.Conv2D(6, kernel_size=(5, 5), strides=1),\n",
    "    #tf.keras.layers.BatchNormalization(),\n",
    "    #tf.keras.layers.Activation('relu'),\n",
    "    # Average Pooling Layer 2: pool size 2x2\n",
    "    tf.keras.layers.AveragePooling2D(pool_size=(2, 2), strides=2),\n",
    "    # Flatten layer to reshape 2D feature maps to a 1D vector\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # Fully Connected Layer 1: 120 units with ReLU activation\n",
    "    tf.keras.layers.Dense(120, activation='sigmoid'),\n",
    "    # TODO: Batch normalization - remove the single line for Dense and replace it by the three following steps\n",
    "    #tf.keras.layers.Dense(120),\n",
    "    #tf.keras.layers.BatchNormalization(),\n",
    "    #tf.keras.layers.Activation('relu'),\n",
    "    # TODO: Dropout\n",
    "    #tf.keras.layers.Dropout(0.5),\n",
    "    # Fully Connected Layer 2: 84 units with ReLU activation\n",
    "    tf.keras.layers.Dense(84, activation='sigmoid'),\n",
    "    # TODO: Batch normalization - remove the single line for Dense and replace it by the three following steps\n",
    "    #tf.keras.layers.Dense(84),\n",
    "    #tf.keras.layers.BatchNormalization(),\n",
    "    #tf.keras.layers.Activation('relu'),\n",
    "    # TODO: Dropout\n",
    "    #tf.keras.layers.Dropout(0.5),\n",
    "    # Output Layer: 10 units with softmax activation for classification\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "    # Originally used Radial Basis Functions in LeNet-5\n",
    "])\n",
    "\n",
    "# Define EarlyStopping callback\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',    # Metric to monitor (e.g., validation loss)\n",
    "    patience=5,            # Number of epochs with no improvement to stop training\n",
    "    restore_best_weights=True  # Restore model weights from the epoch with the best metric value\n",
    ")\n",
    "\n",
    "# Create the Adam optimizer with a specific learning rate\n",
    "adam_optimizer = Adam()  # Set your desired learning rate (default is 0.001, learning_rate is a parameter you can set)\n",
    "\n",
    "# Compile the model\n",
    "model_lenet5.compile(optimizer=adam_optimizer,\n",
    "                     loss='categorical_crossentropy',\n",
    "                     metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history_lenet5 = model_lenet5.fit(X_train_cnn, y_train,\n",
    "                                  epochs=10,\n",
    "                                  batch_size=32,\n",
    "                                  validation_data=(X_test_cnn, y_test),\n",
    "# TODO: Test the early stopping callback\n",
    "#                                  callbacks=[early_stopping],\n",
    "                                  verbose=1)\n",
    "\n",
    "# Plot the learning curves\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(history_lenet5.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history_lenet5.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training and Validation Accuracy for LeNet-5 Architecture\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model_lenet5.evaluate(X_test_cnn, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model_lenet5.predict(X_test_cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Convert predictions from probabilities to class indices\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Compute the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test.argmax(axis=1), predicted_classes)\n",
    "\n",
    "# Display the confusion matrix with class names\n",
    "disp = ConfusionMatrixDisplay(conf_matrix, display_labels=class_names)\n",
    "disp.plot(cmap=plt.cm.Blues, xticks_rotation='vertical')\n",
    "plt.title(\"Confusion Matrix for LeNet Model\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remarks on different topics / Explanation\n",
    "\n",
    "### Normalization\n",
    "Normalization scales input features to a common range, typically [0, 1] or [-1, 1], ensuring that each feature contributes equally to the model's training. It is especially critical when using activation functions like sigmoid or tanh, which are sensitive to input magnitude and can saturate, leading to vanishing gradients. With ReLU, normalization becomes less critical because ReLU does not saturate for positive inputs. However, normalized inputs still help by improving convergence speed and ensuring consistent gradient magnitudes across layers.\n",
    "\n",
    "### Effect of More Data\n",
    "Adding more data can significantly improve model performance, especially by reducing overfitting and enhancing generalization. Models trained on larger datasets can better capture the underlying patterns and variability of the data, leading to improved predictions on unseen samples. However, simply adding more data without diversity or relevance may not yield benefits. High-quality, diverse data ensures that the model is exposed to a wide range of scenarios during training, boosting its ability to generalize.\n",
    "\n",
    "### Dropout and Regularization\n",
    "Dropout is a popular regularization technique that prevents overfitting by randomly setting a fraction of neurons to zero during training. This forces the network to learn more robust features, as it cannot rely on any single neuron. Dropout complements other regularization techniques, such as L2 regularization, which penalizes large weights to reduce model complexity. While dropout is effective, using it excessively can lead to underfitting, so it should be applied judiciously, especially in conjunction with Batch Normalization.\n",
    "\n",
    "### Early Stopping\n",
    "Early stopping halts training when the model's performance on a validation set stops improving for a specified number of epochs. This prevents overfitting, as the model stops learning patterns specific to the training data. By restoring the weights from the epoch with the best validation performance, early stopping ensures optimal generalization. It is particularly effective in scenarios where the model is prone to overfitting or when computational resources are limited.\n",
    "\n",
    "### Batch Normalization\n",
    "Batch Normalization (BatchNorm) normalizes the activations of each layer by adjusting and scaling them during training. This stabilizes learning, reduces the risk of vanishing or exploding gradients, and allows for higher learning rates. BatchNorm also acts as a form of regularization, reducing the need for other techniques like dropout. It is especially useful in deeper networks, where it accelerates convergence and makes the model more robust to weight initialization and learning rate choices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(i, predictions_array, true_array, img):\n",
    "  true_label, img = np.argmax(true_array[i]), img[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "\n",
    "  plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "  if predicted_label == true_label:\n",
    "    color = 'blue'\n",
    "  else:\n",
    "    color = 'red'\n",
    "\n",
    "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                100*np.max(predictions_array),\n",
    "                                class_names[true_label]),\n",
    "                                color=color)\n",
    "\n",
    "def plot_value_array(i, predictions_array, true_array):\n",
    "  true_label = np.argmax(true_array[i])\n",
    "  plt.grid(False)\n",
    "  plt.xticks(range(10))\n",
    "  plt.yticks([])\n",
    "  thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n",
    "  plt.ylim([0, 1])\n",
    "  predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "  thisplot[predicted_label].set_color('red')\n",
    "  thisplot[true_label].set_color('blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first X test images, their predicted labels, and the true labels.\n",
    "# Color correct predictions in blue and incorrect predictions in red.\n",
    "num_rows = 5\n",
    "num_cols = 3\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "  plot_image(i, predictions[i], y_test, X_test_cnn)\n",
    "  plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "  plot_value_array(i, predictions[i], y_test)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7.3 Logistic Regression as a baseline\n",
    "\n",
    "The Fashion MNIST dataset is a more difficult task (overall, still an easy task -- could you explain why?). We want to get a first impression how difficult it actually is and simply apply logistic regression on this dataset as a baseline. And afterwards compute the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Flatten the images back to 1D for logistic regression\n",
    "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test_flat = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "# Train a logistic regression model\n",
    "logistic_regression = LogisticRegression(max_iter=100, multi_class='multinomial', solver='saga', random_state=42)\n",
    "logistic_regression.fit(X_train_flat, y_train.argmax(axis=1))\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = logistic_regression.predict(X_test_flat)\n",
    "\n",
    "# Calculate and print the test accuracy\n",
    "test_accuracy = accuracy_score(y_test.argmax(axis=1), y_pred)\n",
    "print(\"Test accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test.argmax(axis=1), y_pred)\n",
    "\n",
    "# Display the confusion matrix with class names\n",
    "disp = ConfusionMatrixDisplay(conf_matrix, display_labels=class_names)\n",
    "disp.plot(cmap=plt.cm.Blues, xticks_rotation='vertical')\n",
    "plt.title(\"Confusion Matrix for Logistic Regression\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression works not bad on this dataset and seems to generalize also quite well. \n",
    "\n",
    "Why are convolutional neural networks not outperforming logistic regression? How is the structure of the data helpful for other classification methods, but would not be required for convolutional methods?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: right;\">\n",
    "<i>This notebook has been created with the help of ChatGPT-4, 14.11.2024; Explanations were initially generated and afterwards edited;</i>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
